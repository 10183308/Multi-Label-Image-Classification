<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Multi label image classification by suraj-deshmukh</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Multi label image classification</h1>
      <h2 class="project-tagline">The objective of this study is to develop a deep learning model that will identify the natural scenes from images.</h2>
      <a href="https://github.com/suraj-deshmukh/Multi-Label-Image-Classification" class="btn">View on GitHub</a>
      <a href="https://github.com/suraj-deshmukh/Multi-Label-Image-Classification/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/suraj-deshmukh/Multi-Label-Image-Classification/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h1>
<a id="multi-label-image-classification" class="anchor" href="#multi-label-image-classification" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Multi label Image Classification</h1>

<p>The objective of this study is to develop a deep learning model that will identify the natural scenes from images. This type of problem comes under multi label image classification where an instance can be classified into multiple classes among the predefined classes.</p>

<h1>
<a id="dataset" class="anchor" href="#dataset" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Dataset</h1>

<p>The complete description of dataset is given on <a href="http://lamda.nju.edu.cn/data_MIMLimage.ashx">http://lamda.nju.edu.cn/data_MIMLimage.ashx</a>. The dataset contains 2000 natural scenes images.</p>

<h1>
<a id="keras-model-architecture" class="anchor" href="#keras-model-architecture" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Keras Model Architecture</h1>

<p><img src="https://github.com/suraj-deshmukh/Multi-Label-Image-Classification/blob/master/model.png" alt="all tag"></p>

<h1>
<a id="preprocessing" class="anchor" href="#preprocessing" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Preprocessing</h1>

<p>Resized all images to 100 by 100 pixels and created two sets i.e train set and test set. Train set contains 1600 images and test set contains 200 images.</p>

<h1>
<a id="training" class="anchor" href="#training" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Training</h1>

<p>As this is multi label image classification, the loss function was binary crossentropy and activation function used was sigmoid at the output layer. Keras doesn't have provision to provide multi label output so after training there is one probabilistic threshold method which find out the best threshold value for each label seperately, the performance of threshold values are evaluated using Matthews Correlation Coefficient and then uses this thresholds to convert those probabilites into one's and zero's.</p>

<h1>
<a id="result" class="anchor" href="#result" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Result</h1>

<p>Below table shows the result on test set</p>

<table>
<thead>
<tr>
<th>Accuracy</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hamming loss</td>
<td>0.1395</td>
</tr>
<tr>
<td>Exact Match</td>
<td>0.54</td>
</tr>
</tbody>
</table>

<h1>
<a id="preprocessed-dataset-and-weight-file-download-link" class="anchor" href="#preprocessed-dataset-and-weight-file-download-link" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Preprocessed Dataset and Weight file download link</h1>

<p>dataset: <a href="https://drive.google.com/open?id=0BxGfPTc19Ac2a1pDd1dxYlhIVlk">https://drive.google.com/open?id=0BxGfPTc19Ac2a1pDd1dxYlhIVlk</a></p>

<p>weight file: <a href="https://drive.google.com/open?id=0BxGfPTc19Ac2X1RqNnEtRnNBNUE">https://drive.google.com/open?id=0BxGfPTc19Ac2X1RqNnEtRnNBNUE</a></p>

<h1>
<a id="ipython-notebook" class="anchor" href="#ipython-notebook" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Ipython notebook</h1>

<p>Jupyter/iPython Notebook has been provided to know about the model and its working. <a href="https://github.com/suraj-deshmukh/Multi-Label-Image-Classification/blob/master/miml.ipynb">https://github.com/suraj-deshmukh/Multi-Label-Image-Classification/blob/master/miml.ipynb</a> </p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/suraj-deshmukh/Multi-Label-Image-Classification">Multi label image classification</a> is maintained by <a href="https://github.com/suraj-deshmukh">suraj-deshmukh</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
